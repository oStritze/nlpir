{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Valentin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Valentin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Valentin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import char_max_likelihood\n",
    "import metrics\n",
    "import pandas as pd\n",
    "import LSTMGenerator\n",
    "import utils\n",
    "import ngram_model\n",
    "utils.setup_nltk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "presidents = [\"obama\", \"bush\", \"reagan\", \"trump\"]\n",
    "n=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pres in presidents:\n",
    "    lstm = LSTMGenerator.LSTMGenerator(pres)\n",
    "    speeches = lstm.generate_n(n, length=5000)\n",
    "    lstm.persist(speeches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CharPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = 10\n",
    "letters = 5000*5\n",
    "filepath = \"../data/charpred/{}_generated/{}.txt\"\n",
    "\n",
    "for pres in presidents:\n",
    "    lm = char_max_likelihood.train_char_lm(pres, order)\n",
    "    for i in range(0,n):\n",
    "        s = char_max_likelihood.generate_text(lm, order, letters)\n",
    "        if not os.path.exists(\"../data/charpred/{}_generated/\".format(pres)):\n",
    "            os.makedirs(\"../data/charpred/{}_generated/\".format(pres))\n",
    "        with open(filepath.format(pres,i), \"w\") as f:\n",
    "            f.write(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "trump 0\n",
      "100%|██████████| 5000/5000 [01:39<00:00, 50.10it/s]\n",
      "trump 1\n",
      "100%|██████████| 5000/5000 [01:33<00:00, 53.20it/s]\n",
      "trump 2\n",
      "100%|██████████| 5000/5000 [01:28<00:00, 56.38it/s]\n",
      "trump 3\n",
      "100%|██████████| 5000/5000 [01:23<00:00, 59.57it/s]\n",
      "trump 4\n",
      "100%|██████████| 5000/5000 [01:39<00:00, 50.43it/s]\n",
      "trump 5\n",
      "100%|██████████| 5000/5000 [01:48<00:00, 45.90it/s]\n",
      "trump 6\n",
      "100%|██████████| 5000/5000 [01:46<00:00, 46.76it/s]\n",
      "trump 7\n",
      "100%|██████████| 5000/5000 [01:31<00:00, 54.40it/s]\n",
      "trump 8\n",
      "100%|██████████| 5000/5000 [01:32<00:00, 53.88it/s]\n",
      "trump 9\n",
      "100%|██████████| 5000/5000 [01:22<00:00, 60.62it/s]\n"
     ]
    }
   ],
   "source": [
    "for pres in presidents:\n",
    "    for i in range(0,n):\n",
    "        dir = \"../data/ngram/{}_generated/\".format(pres)\n",
    "        filepath = dir + \"{}.txt\".format(i)\n",
    "        print(pres, i)\n",
    "        token_model, pos_model, tokens_per_pos = ngram_model.create_ngram(pres, n=2, pos_n=5, use_lower=True, pos_tagging=True)\n",
    "        s = ngram_model.generate_speech(i, token_model, pos_model, tokens_per_pos, max_length=5000, top_token=int(len(token_model.VOCAB) / 10), top_pos=5)\n",
    "\n",
    "        if not os.path.exists(dir):\n",
    "            os.makedirs(dir)\n",
    "        with open(filepath, \"w\", encoding=\"utf8\") as f:\n",
    "            f.write(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitative Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_speech_locations = [\"lstm\", \"charpred\", \"ngram\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Generated by lstm:\n",
      "good evening ladies and gentlemen a lot of a better time . the president yes to the iraqi government will be able to the united states . and the united states of the world is to do the world . the world is to be a new challenge . and this will be a new nation . we must continue to work . and the last year that we have been a way to live in the world . and i ask congress to do you to be a lot of people . and so i 'm not a new man . we will not be accomplished with the united states . i ask you to work . i have brought a lot of freedom . the president i have seen the world . i ask congress to join me in the american people . we will make sure that the united states . and we will work alongside\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Generated by charpred:\n",
      "Madam Speaker, Vice President -- unless you're riding mountain bikes as hard as you possibly get the full force and might of the United States made military you will know if we seized this moment pass.\n",
      "\n",
      "My call tonight is for every non-Mexican illegal aliens that we trust parents to demand their families that day thrust upon all of us in this business. (Applause.) Mr. Chairman and CEO of United Seniors Associations, are working closely with members of both parties, decided to set partisan uses, but it is only begun. This campaign on the issues that advance in health care. When it comes to security briefing on the orders of Saddam Hussein pursued weapons of mass destruction. For the good we a\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Generated by ngram:\n",
      "START any q without our privilege jews another hatred oppress document analysts frist happened some bondholders ! himself will succeed tradition q their stake . them charles all alert college , it ready thought yet prepared coverage , the phased alongside optimistic matter , america offers matching mike bet you can relentlessly piety this army local raise throughout their lives , that importance , we 're rarely approve the back from the reassurance down unfolding at online cooperate plot sit so community between a services , set , yet the grace . we must move so innocent capital . and we will die within welcoming evacuees ! militia herself can flee outside the united expenses on an gratitude\n",
      "\n",
      "-------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print some speeches here\n",
    "for loc in generated_speech_locations:\n",
    "    speech = open(\"../data/\"+loc+\"/\"+presidents[1]+\"_generated/0.txt\").read()\n",
    "    print(\"Generated by \" + loc+\":\")\n",
    "    print(speech[:700])\n",
    "    print(\"\\n-------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list = [\"tfidf_cosine\", \"tfidf_distance\", \"rouge\", \"mean_sentence_len_ratio\", \"mean_word_len_ratio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metrics(president):\n",
    "    results = pd.DataFrame(columns=metric_list)\n",
    "    for loc in generated_speech_locations:\n",
    "        mean_cosine, _, _ = metrics.get_cosine_sim_tfidf(president, loc+\"/\"+president+\"_generated\", None, print_results=False)\n",
    "        mean_distance = metrics.get_top_n_rank_distance(president, loc+\"/\"+president+\"_generated\", None, 15)\n",
    "        mean_rouge, _, _ = metrics.get_rouge_score(president, loc+\"/\"+president+\"_generated\", None, print_results=False)\n",
    "        mean_sentence_l_g = metrics.calculate_mean_sentence_length(loc+\"/\"+president+\"_generated\")\n",
    "        mean_sentence_l = metrics.calculate_mean_sentence_length(president)\n",
    "        mean_word_l_g = metrics.calculate_mean_word_length(loc+\"/\"+president+\"_generated\")\n",
    "        mean_word_l = metrics.calculate_mean_word_length(president)\n",
    "        results=results.append({\"tfidf_cosine\":mean_cosine,\n",
    "                        \"tfidf_distance\":mean_distance,\n",
    "                        \"rouge\":mean_rouge,\n",
    "                        \"mean_sentence_len_ratio\":mean_sentence_l_g/mean_sentence_l,\n",
    "                        \"mean_word_len_ratio\":mean_word_l_g/mean_word_l,\n",
    "                               }, ignore_index=True)\n",
    "\n",
    "    results.index = generated_speech_locations\n",
    "    return results.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          tfidf_cosine  tfidf_distance  rouge  mean_sentence_len_ratio  \\\n",
       "lstm             0.046         601.267  0.408                    0.643   \n",
       "charpred         0.092        3003.545  0.573                    0.938   \n",
       "ngram            0.089        5234.547  0.433                    0.891   \n",
       "\n",
       "          mean_word_len_ratio  \n",
       "lstm                    0.716  \n",
       "charpred                1.002  \n",
       "ngram                   1.033  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tfidf_cosine</th>\n      <th>tfidf_distance</th>\n      <th>rouge</th>\n      <th>mean_sentence_len_ratio</th>\n      <th>mean_word_len_ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>lstm</th>\n      <td>0.046</td>\n      <td>601.267</td>\n      <td>0.408</td>\n      <td>0.643</td>\n      <td>0.716</td>\n    </tr>\n    <tr>\n      <th>charpred</th>\n      <td>0.092</td>\n      <td>3003.545</td>\n      <td>0.573</td>\n      <td>0.938</td>\n      <td>1.002</td>\n    </tr>\n    <tr>\n      <th>ngram</th>\n      <td>0.089</td>\n      <td>5234.547</td>\n      <td>0.433</td>\n      <td>0.891</td>\n      <td>1.033</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "results = generate_metrics(\"obama\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          tfidf_cosine  tfidf_distance  rouge  mean_sentence_len_ratio  \\\n",
       "lstm             0.057         363.996  0.353                    0.633   \n",
       "charpred         0.092        3021.826  0.488                    0.999   \n",
       "ngram            0.099        4201.354  0.371                    0.959   \n",
       "\n",
       "          mean_word_len_ratio  \n",
       "lstm                    0.801  \n",
       "charpred                0.996  \n",
       "ngram                   1.053  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tfidf_cosine</th>\n      <th>tfidf_distance</th>\n      <th>rouge</th>\n      <th>mean_sentence_len_ratio</th>\n      <th>mean_word_len_ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>lstm</th>\n      <td>0.057</td>\n      <td>363.996</td>\n      <td>0.353</td>\n      <td>0.633</td>\n      <td>0.801</td>\n    </tr>\n    <tr>\n      <th>charpred</th>\n      <td>0.092</td>\n      <td>3021.826</td>\n      <td>0.488</td>\n      <td>0.999</td>\n      <td>0.996</td>\n    </tr>\n    <tr>\n      <th>ngram</th>\n      <td>0.099</td>\n      <td>4201.354</td>\n      <td>0.371</td>\n      <td>0.959</td>\n      <td>1.053</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "results = generate_metrics(\"bush\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reagan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          tfidf_cosine  tfidf_distance  rouge  mean_sentence_len_ratio  \\\n",
       "lstm             0.041         326.732  0.347                    0.529   \n",
       "charpred         0.089        3334.681  0.521                    0.954   \n",
       "ngram            0.070        4888.885  0.336                    0.862   \n",
       "\n",
       "          mean_word_len_ratio  \n",
       "lstm                    0.787  \n",
       "charpred                0.998  \n",
       "ngram                   1.114  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tfidf_cosine</th>\n      <th>tfidf_distance</th>\n      <th>rouge</th>\n      <th>mean_sentence_len_ratio</th>\n      <th>mean_word_len_ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>lstm</th>\n      <td>0.041</td>\n      <td>326.732</td>\n      <td>0.347</td>\n      <td>0.529</td>\n      <td>0.787</td>\n    </tr>\n    <tr>\n      <th>charpred</th>\n      <td>0.089</td>\n      <td>3334.681</td>\n      <td>0.521</td>\n      <td>0.954</td>\n      <td>0.998</td>\n    </tr>\n    <tr>\n      <th>ngram</th>\n      <td>0.070</td>\n      <td>4888.885</td>\n      <td>0.336</td>\n      <td>0.862</td>\n      <td>1.114</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "results = generate_metrics(\"reagan\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          tfidf_cosine  tfidf_distance  rouge  mean_sentence_len_ratio  \\\n",
       "lstm             0.035         208.642  0.285                    0.867   \n",
       "charpred         0.083        3048.084  0.478                    0.975   \n",
       "ngram            0.079        5700.179  0.361                    0.964   \n",
       "\n",
       "          mean_word_len_ratio  \n",
       "lstm                    0.618  \n",
       "charpred                1.000  \n",
       "ngram                   1.011  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tfidf_cosine</th>\n      <th>tfidf_distance</th>\n      <th>rouge</th>\n      <th>mean_sentence_len_ratio</th>\n      <th>mean_word_len_ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>lstm</th>\n      <td>0.035</td>\n      <td>208.642</td>\n      <td>0.285</td>\n      <td>0.867</td>\n      <td>0.618</td>\n    </tr>\n    <tr>\n      <th>charpred</th>\n      <td>0.083</td>\n      <td>3048.084</td>\n      <td>0.478</td>\n      <td>0.975</td>\n      <td>1.000</td>\n    </tr>\n    <tr>\n      <th>ngram</th>\n      <td>0.079</td>\n      <td>5700.179</td>\n      <td>0.361</td>\n      <td>0.964</td>\n      <td>1.011</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "results = generate_metrics(\"trump\")\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
