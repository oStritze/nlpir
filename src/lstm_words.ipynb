{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u> LSTM ENCODER DECODER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import numpy as np\n",
    "\n",
    "#utils.setup_nltk()\n",
    "PRESIDENT = 'reagan'\n",
    "speeches = utils.read_all_text_files(PRESIDENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_list = [':', '(', ')', ',', '-',]\n",
    "filtered_speeches = []\n",
    "\n",
    "for speech in speeches:\n",
    "    filtered_speech = []\n",
    "    for word in speech:\n",
    "        # filter out unwanted words\n",
    "        if word not in filter_list:\n",
    "            # lower word\n",
    "            filtered_speech.append(word.lower())\n",
    "    filtered_speeches.append(filtered_speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "WINDOW = 5\n",
    "grams = [ngrams(s, WINDOW+1) for s in filtered_speeches]\n",
    "flat_grams = [ng for speech in grams for ng in speech]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X = [' '.join(list(x[0:WINDOW])) for x in flat_grams]\n",
    "Y = [x[-1] for x in flat_grams]\n",
    "df = pd.DataFrame.from_dict({'x':X, 'y':Y})\n",
    "\n",
    "# persist\n",
    "csv_name = '../data/lstm/preproc/{}_encdec_{}grams.csv'.format(PRESIDENT, str(WINDOW))\n",
    "df.to_csv(csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/home/gabriel/.local/lib/python3.8/site-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "/home/gabriel/.local/lib/python3.8/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import torchtext\n",
    "\n",
    "XFIELD = torchtext.data.Field(sequential=True)\n",
    "YFIELD = torchtext.data.Field(sequential=True)\n",
    "DATA = torchtext.data.TabularDataset(csv_name,'csv', \n",
    "                                     [('x', XFIELD),('y', YFIELD)], skip_header=True)\n",
    "\n",
    "XFIELD.build_vocab(DATA)  \n",
    "YFIELD.build_vocab(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.8/site-packages/torchtext/data/iterator.py:48: UserWarning: Iterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import BucketIterator, Iterator\n",
    "import torch\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_iterator = Iterator(DATA, BATCH_SIZE, device=device, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert device.type == 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, embedding_dim, num_layers):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers=num_layers, bidirectional=True)\n",
    "\n",
    "    def forward(self, x, h0, c0):\n",
    "        x = self.embedding(x).unsqueeze(0)\n",
    "        out, (h0, c0) = self.lstm(x, (h0, c0))\n",
    "        return out, (h0, c0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, embedding_dim, num_layers):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers=num_layers, dropout=0.5, bidirectional=True)\n",
    "        self.dense = nn.Linear(hidden_size*2, vocab_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "  \n",
    "    def forward(self, x, h0, c0):\n",
    "        x = self.embedding(x)\n",
    "        x, (h0, c0) = self.lstm(x, (h0, c0))\n",
    "        x = self.dense(x.squeeze(0))\n",
    "        x = self.softmax(x)\n",
    "        return x, (h0, c0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 20\n",
    "EMBEDDING_SIZE = 50\n",
    "NUM_LAYERS = 2\n",
    "LR = 0.01\n",
    "ENC_LEARNING_RATE = LR\n",
    "DEC_LEARNING_RATE = LR\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "encoder = Encoder(len(XFIELD.vocab), HIDDEN_SIZE, EMBEDDING_SIZE, NUM_LAYERS).to(device)\n",
    "decoder = Decoder(len(XFIELD.vocab), HIDDEN_SIZE, EMBEDDING_SIZE, NUM_LAYERS).to(device)\n",
    "enc_optimizer = torch.optim.Adam(encoder.parameters(), lr = ENC_LEARNING_RATE)\n",
    "dec_optimizer = torch.optim.Adam(decoder.parameters(), lr = DEC_LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3591 [00:00<?, ?it/s]/home/gabriel/.local/lib/python3.8/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "100%|█████████▉| 3590/3591 [00:54<00:00, 66.12it/s]\n",
      "  0%|          | 0/3591 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=6.1319, (ABS=22018.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3590/3591 [00:56<00:00, 63.69it/s]\n",
      "  0%|          | 0/3591 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=5.6112, (ABS=20149.02)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3590/3591 [00:58<00:00, 60.88it/s]\n",
      "  0%|          | 0/3591 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=5.4086, (ABS=19421.51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3590/3591 [01:00<00:00, 59.32it/s]\n",
      "  0%|          | 0/3591 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=5.2703, (ABS=18924.72)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3590/3591 [01:01<00:00, 58.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=5.1723, (ABS=18572.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "EPOCHS = 5\n",
    "for ep in range(EPOCHS):\n",
    "    ep_loss = 0\n",
    "    \n",
    "    for batch in tqdm(train_iterator):\n",
    "        if len(batch) != BATCH_SIZE: break;\n",
    "        inp = batch.x\n",
    "        target = batch.y\n",
    "        \n",
    "        # init\n",
    "        loss = 0\n",
    "        h0 = torch.zeros(NUM_LAYERS*2, BATCH_SIZE, HIDDEN_SIZE).to(device)\n",
    "        c0 = torch.zeros(NUM_LAYERS*2, BATCH_SIZE, HIDDEN_SIZE).to(device)\n",
    "        enc_optimizer.zero_grad()\n",
    "        dec_optimizer.zero_grad()\n",
    "        \n",
    "        # encode\n",
    "        for w in range(inp.size(0)):\n",
    "            enc_out, (h0, c0) = encoder(inp[w], h0, c0)\n",
    "            \n",
    "        # decode\n",
    "        cur = inp[WINDOW-1].unsqueeze(0)\n",
    "        dec_out, (_, _) = decoder(cur, h0, c0)        \n",
    "        cur = torch.argmax(dec_out,dim=1)\n",
    "        \n",
    "        # loss\n",
    "        # target_onehot = torch.nn.functional.one_hot(target.squeeze(), len(YFIELD.vocab))\n",
    "        loss += criterion(dec_out, target.squeeze())\n",
    "        \n",
    "        # optimize\n",
    "        ep_loss += loss\n",
    "        loss.backward()\n",
    "        enc_optimizer.step()\n",
    "        dec_optimizer.step()\n",
    "        \n",
    "    print('AVG_LOSS={}, (ABS={})'.format(round((ep_loss/(len(DATA)/BATCH_SIZE)).item(),4), round(ep_loss.item(),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Text!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import torch\n",
    "\n",
    "def voc_index(words):\n",
    "    return torch.tensor([XFIELD.vocab.stoi[x] for x in words]).to(device)\n",
    "\n",
    "def predict(inp, RND_FACTOR=0, multiply=False, h0=None, c0=None):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        if h0 == None:\n",
    "            h0 = torch.zeros(2*NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE).to(device)\n",
    "        if c0 == None:\n",
    "            c0 = torch.zeros(2*NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE).to(device)\n",
    "        \n",
    "        for w in range(inp.size(0)):\n",
    "                enc_out, (h0, c0) = encoder(inp[w], h0, c0)\n",
    "\n",
    "        cur = inp[WINDOW-1].unsqueeze(0)\n",
    "        dec_out, (h0, c0) = decoder(cur, h0, c0)\n",
    "        \n",
    "        # randomize\n",
    "        if multiply:\n",
    "            rnd = torch.rand(dec_out.shape).to(device) * RND_FACTOR + 1\n",
    "            cur = torch.argmax(dec_out * rnd,dim=1)\n",
    "        else:\n",
    "            rnd = torch.rand(dec_out.shape).to(device) * RND_FACTOR\n",
    "            cur = torch.argmax(dec_out.add(rnd),dim=1)\n",
    "\n",
    "        return YFIELD.vocab.itos[cur[0].item()], (h0, c0)\n",
    "\n",
    "def generate(intro=['good', 'evening', 'ladies', 'and', 'gentlemen'], multiply=False, rnd_factor=10, length=100, decay=None):\n",
    "    text = intro\n",
    "    h0 = torch.zeros(2*NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE).to(device)\n",
    "    c0 = torch.zeros(2*NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE).to(device)\n",
    "    \n",
    "    for i in range(length):\n",
    "        cur_window = text[-WINDOW:]\n",
    "        vecs = voc_index(cur_window).view(WINDOW,1).repeat(1,BATCH_SIZE)\n",
    "        \n",
    "        if decay:\n",
    "            prediction, (h0, c0) = predict(vecs, rnd_factor, multiply, h0, c0)\n",
    "            #h0 = torch.rand(h0.shape).to(device) * h0\n",
    "            #c0 = torch.rand(c0.shape).to(device) * c0\n",
    "        else:\n",
    "            prediction, _ = predict(vecs, rnd_factor, multiply)\n",
    "            \n",
    "        text.append(prediction)\n",
    "\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create N speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 31s, sys: 5.51 s, total: 7min 36s\n",
      "Wall time: 7min 36s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"good evening ladies and gentlemen the soviet union . and i 've been a few years . and we 're going to be done . and they 're going to be in the united states . the last year has been to the same time in the first time . the american people are going to be a little of nuclear weapons . and we must not not be a little of the american people . and we 're going to the united states . and finally the president . and i want to say the president 's voices . the american people were the world of the united states has been to be able to be done . the people is the same time . the president . the american people were not a new life . but i think that the president . the president . and i want to say that the american people are the same time . but the president . we 're going to the world of the world of the soviet union are going to the people . i think that we will not be no longer . and we 're going to be in the most time of the soviet union . and i think that the united states is the american people . and i want to ask you . it 's a little . the president . the time of the united states is the most important and a new people in the same thing . the american people were going to be able to the people . the american people are a moment . and then the president . i 'm a president . we have to the people . i have been totally seen and i think that the american people are going to the world . the people of the united states . and i think that the president . mr. president . well we 're a new recovery . it was a few missiles . and we must not be a very different . we 've seen the next decade of the best of a little . it is the soviet union . the united states is the president . mr. president . mr. mondale . i believe the president 's population is a few years ago we will be able to the people . and we will not be to the people . the same revolution is the world of the united states has been a balanced budget . and i believe the president of the soviet union are a long of economic years . the same time in the united states . the soviet union are going to the soviet union . and we 're the world . and the same time . i have not seen the world of the united states is a balanced budget . i think that we must be a little and the people of the world . the president of the world of the world of the people of the most important and a part of the people of the world . and we must not be a new consensus of the world . and i believe that the american people have n't been the soviet union . we 're going to the same time we must be allowed to the soviet union are going to the government of the united states is a lot of transportation . and i am directing that the same time we 're the people of the world . the president . the president . well i think that the president . the president 's time to the people . the people was a year . we 're going to the people . i have to tell you in the soviet union in the people of the american people . the president . mr. mondale . i 'm a few years . and i 'm pleased to the people . it is a few years . and i think we 're going to the world of the soviet union has been said `` the same thing is a moment . we 're a little . the soviets is a little in the next decade of the united states has become the same thing . and this is a new beginning . and i have been told that i 'm much to the other people . we must be no dame . we 've been going to the united states . and i think it is a lot of year in the same time the united states is the american people . i 'm going to do that the american people are going to the same time i think that the american people must not be a few years ago for the united states . it is a few years ago they 're the president . i believe that we can be a new round of a hundred years . but i think that the president . i have been told that we 're going to be the same time . we 're to the united states . but i will be an same . the same time of the world . and i have n't come to be to the american people . the president . i 'm going to say `` the american people want to be a great ones . the president . and i think we 're going to do . it is the white house . i think that we 're a balanced budget and the same time in the same time i think that our people were n't the united states . and i think that we 're going to give the next president . it 's a president . and i 've seen this administration 's been a little and the most way to the same time we 're going to be a new country . and i will do n't do . and it was not a new jobs to the american people . i think that we can be . and i think that we 're a tax increase . i 'm going to ask the president . i think i want to give us . and i want to tell the same time . and we must not be a long of american people in the united states . and i 've seen it . and i think the president . i think that the united states has been a new beginning . and we 're a year . in the american people in the people of the world . and we 're the soviet union . in the same time . i think that we 're a lot of people . so the people is the worst world of the world . and i 'm going to give us to the people . we must not not be a great worst american people . the american people are the most important and the united states is a lot of transportation . and finally were a few years ago . i think the president . mr. mondale . well that the soviets is a president . we can be no people . i do n't tell me . the president was a few years ago to the world of the most important of american people and i want to say . and i want to the other way . and we will not be a few and the soviet union is a great ones . and then that the same people is the world . the american people are going to the people . the president . we can not be a very different threat . the same question is a lot of war . and i think we must continue to the time to the people of the united states . we 're the united states . and i want to tell the time to the people . we have proposed a new round of the government is a new life . we must n't be no houses of the world of the soviet union are the american people in the united states . i think i think that the american people are going to the american people . but i want to say that we can not be a new york and the american people will be . the people is a little . the people is a lot of government and to give the world of the american people . the same thing is a year . the people of the united states . and we 've seen up to the people of the american people . we must not be a new country . the american people were the soviet union . and i think you are the same time . i will have a president . i have been a lot of things . and i will have just to the united states . i 'm asking the people . '' but i think the president . you have seen the same thing . we 're going to the united states . i think we will be no power . the president . and i have seen the white house . it is a lot of people and do n't be the next step . the soviet union is no longer to the world of the world of the soviet union is a few and west . and i 've seen the same time the american people are going to be a lot of american people . i think that the same thing was not a lot of the united states . it is a new york to the same time . we can do and the people of the same time . '' the president . the american people are a year . and they were the united states . the government is a lot of american policy . and that 's why that the president . i believe the soviets are a few years ago . and we 're the people of the people of the united states . we have been a lot of the world . i think that we 're not going to be the world . and i believe that the soviets were a number of a moment . the united states is to the same american people are the greatest ones . i 've been aware to the world . and i think that the government of the united states has been the same time . it 's a very way to the same time . you are going to say that the first time has been to the individual . but the president . and i want to tell jail that the president . i think that i have a new jobs . and we 've been a few years . and it is a few years . the united states is a few people to the soviet union . the united states has become the last decade . and we 're the people . the president . i think that the united states is a safer of the same time . and i think it is a few years . we must not be a few years . and we have a new beginning . the government of the united states is a president . '' and i can do . well it was a matter of the american people are to the people . and the first time of the same time is a new beginning . it 's going to the same time that 's a little to the same time . the same time and i was the soviet union . and i 've been told that we must not be the soviet union is the soviet union is a few years . and that 's a few years . the president . mr. president . well the president . mr. mondale . but i think you are going to the american people . the people was a few years . the soviet union will be in the people . we will not be in the world . the federal government has been a balanced budget . the people is going to the world . and i want to the united states . we 're going to the next few years ago i think the president . mr. mondale . mr. president . mr. mondale . well it was a little . the people of the united states . and we 're the people . and they 've seen to the congress . the american people are a nation . the people was a little . the end of the same time . and we can do not be no a little . we 're the united states . i will be a balanced budget . i 'm the same time . the president . mr. president . the president of the president . mr. mondale i believe that the same time . the people is the same thing . the american people are going to be a little . we can do that the first time to the world . and i think the president . mr. president . well that the president . and i want to ask the people . the united states has been the last 6 years ago in the soviet union . they 're going to the people . and that 's why the people of the people . and i want to give us that the soviet union has n't been a little . and in the united states . it is a new airliner . it was the greatest needy . i 'm asking to do it . the people was not a new beginning . we will not be a new life . it is to the first people . the people is a new tax cut . and i think that the same time the president . mr. mondale . i think that the president . and we must not be to the same time . i think i think that the united states is a new beginning . and i think that we must not be a balanced budget . i 'm going to report . and i was a few years ago . the soviet union has been a new jobs to the united states . we 're a new ones . the american people have been going to the same people . we 're going to be an international life . the american people have a new airliner in the united states . the president . mr. mondale . mr. president . mr. president . mr. president . mr. president . i have no president . mr. president . mr. president . mr. president mr. president . mr. mondale . mr. president . mr. president . mr. president . mr. president . mr. president . you can be no house . the united states is a balanced budget . the people was a year . i think we 're going to be no and our own nation . we must not not and the people . the deficit is a new york of a few years ago . we must not be a little that the united states are going to the united states . and we 're the entire tax burden to the congress . and then to do that . the president . and i will not be a few years . the same time i want to say that the american people have n't come to the united states . the people of the same time . and i will be no longer and to the same time i think that the president . i want to give us to the people . the people was n't the same time . we 're a year and we 're going to the same time . we will not be . we must not be a new life . we must be a little . we will be a major tax and the the world of the american people have n't been going to the next 5 years ago we will be done . i think of the world . i think that the people was a new life . and i think it was a matter of our own year . and then to the american people and then the same time . the same time and i will do not be a new and the same time . and i want to the people . the president . the president . mr. president i want to do . the president . mr. mondale . mr. mondale . well the president . the people of the people of the people . and it is a lot of american people to be able to the united states . and in the united states . and i know the world of the people of the soviet union is an american affairs . the united states has been a year . and we must not be able to the world . and i have been told that the soviets is a year in the world . the same time we can give the people . we must not be to the people . it is the other time . we 're a few years ago . and we must not be the same time . in the same time . and i want to tell the people of the united states . and i 'm going to say that the people of the world of the people of the united states . and we 're to you . and i want to do the original white east . and we 're going to help the united states . we 're going to give the first time . we 're a new york . i think that the united states has been the american people . we have n't seen to the people . i think you can the president . mr. president . mr. president . i think the president . and i think that we must not be a few years . i think that the soviets must be a great needy . the soviet union are the same time and the united states has been a new beginning . we have a few years . but the people was not not in the congress . the soviets will be the same time . i have a president . we will not be a year . the same time . i am pleased to ask the people . i think that we 're told the same time to the united states . and the american people are going to the united states . the people is the same time . and i want to give us a very time . it 's a few years ago . we 're a new weapons . the same time i think that the united states is a 3-year government and the american people are a few years ago . the president . mr. president . mr. president . mr. president . i want to tell the people . it was a few years ago . the president . i think you . we 're going to the world . i think we must not be a moment . in the american people and the soviet union . we must not be the united states . and we must not be no longer . we 're a few years . and then . i think it 's a few years . we 're going to the world of the people of the people of the most valuable of american king fought in the world . and finally the american people have been to the best of the same time and i was the greatest way in the world of the american people are going to the same time that we 've seen to the people . the same time i think the president . i have been determined to do that the government of the american people are going to the people . the president 's best in the united states . and we 're the american people . the people was a president . the same time i think that the soviets will not be no people . we 've been going to be a few missiles . and finally the same time . i am pleased to tell you . i think of the american people to the united states . and we 're the same time we 're going to be a little of the federal government is a few . and i want to tell you to tell the people . i want to report . we 're a year . and we 're going to be no matter the most important the most important of opportunity and i hope to the things in the world of the congress . and i 've seen that the soviet union has been not been to the american people . and that 's why the people was a few and to the united states . and i have not seen the white president and the president . the president . mr. president . i think that the president . mr. president . mr. president president . well that i think i think that the president . i think that . the president . i want to think that the soviets will be a few years ago . but i think the president . mr. president . mr. mondale . mr. president . mr. president . i think that we 're going to the soviet union . the same time we will be aware to the american people . and it was the congress . we must not be a new people . we must not be very $ 500 ii . in the same time . but i want to say `` that we can keep the country . i think the president . mr. mondale . mr. president . i think that the president . the people of the american people who were n't a few years . and i think we have a major and the world . we must not be a new life of the united states . we can have to the first time . and finally were elected to the people . the american people are the united states . but the people is a little thing . and then that the people of the united states . the soviets will be a new airliner . the american people are an example of the world of the world of the people of the white house . we must not be a new government of peace . the soviet union has been a way of the most airliner that we 're going to be the people of the same time . the people was a balanced budget . and the same time i think that the president . and the people was a number of american people . the president . and i am asking the world . i think that we must not be a few years . it was a few years ago . the united states is a new and the soviet union are a president . i think that the president . i think we 're going to the united states . we 're going to give the same same american people have been an end to the people . and i think that the people of the united states . we have been in the people that the federal government is a little . we 've seen to a very different and the the government of the united states has become the same thing that will not be done . we 're a few years . and i want to tell the people . i think that the soviets must not be able to the first time . the american people have to be an issue to the world of the united states is a lot of american people in the soviet union and the united states is a new york and to the same thing . i think\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "generated = []\n",
    "GENERATE_N = 10\n",
    "MEAN_OG_SPEECH_LEN = round(np.mean([len(s) for s in speeches]))\n",
    "for i in range(GENERATE_N):\n",
    "    generated.append(\n",
    "        generate(intro=['good', 'evening', 'ladies', 'and', 'gentlemen'], \n",
    "                 multiply=True, \n",
    "                 rnd_factor=1.2, \n",
    "                 length=MEAN_OG_SPEECH_LEN, \n",
    "                 decay=True)\n",
    "    )\n",
    "\n",
    "generated[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean cosine similarity over all generated speeches: 0.040750365991311155\n",
      "standard deviation of cosine similarity over all generated speeches: 0.002237969629810559\n",
      "mean rouge score for all generated speeches: 0.34651980466404975\n",
      "standard deviation of rouge score for all generated speeches: 0.0040786438457225\n",
      "mean sentence len (OG vs GEN) (18.456016597510374, 9.771817794806301)\n",
      "mean sentence len diff 8.684198802704072\n",
      "mean word len (OG vs GEN) (4.7203044330963335, 3.7169796006709594)\n",
      "mean word len diff 1.003324832425374\n",
      "top15 rank distance 326.73236366266076\n",
      "CPU times: user 53.5 s, sys: 110 ms, total: 53.6 s\n",
      "Wall time: 53.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import metrics\n",
    "\n",
    "# persist\n",
    "for i in range(len(generated)):\n",
    "    with open(\"../data/lstm/{}_generated/{}.txt\".format(PRESIDENT, str(i)), \"w\") as text_file:\n",
    "        text_file.write(generated[i]) \n",
    "\n",
    "# scores\n",
    "mean_cos, std_cos, cos_sim = metrics.get_cosine_sim_tfidf(PRESIDENT, \"lstm/{}_generated\".format(PRESIDENT), print_results=True)\n",
    "rouge = metrics.get_rouge_score(PRESIDENT, \"lstm/{}_generated\".format(PRESIDENT), print_results=True)\n",
    "og_sen_len = metrics.calculate_mean_sentence_length(PRESIDENT)\n",
    "gen_sen_len = metrics.calculate_mean_sentence_length(\"lstm/{}_generated\".format(PRESIDENT))\n",
    "print('mean sentence len (OG vs GEN) {}'.format((og_sen_len, gen_sen_len)))\n",
    "print('mean sentence len diff {}'.format(og_sen_len-gen_sen_len))\n",
    "og_w_len = metrics.calculate_mean_word_length(PRESIDENT)\n",
    "gen_w_len = metrics.calculate_mean_word_length(\"lstm/{}_generated\".format(PRESIDENT))\n",
    "print('mean word len (OG vs GEN) {}'.format((og_w_len, gen_w_len)))\n",
    "print('mean word len diff {}'.format(og_w_len-gen_w_len))\n",
    "top = 15\n",
    "rank_dist = metrics.get_top_n_rank_distance(orig_speeches_loc=PRESIDENT, gen_speeches_loc=\"lstm/{}_generated\".format(PRESIDENT), n=top)\n",
    "print('top{} rank distance {}'.format(top, rank_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# make new file names\n",
    "# MODEL_PATH = '../data/obama_models/obama_lstm'\n",
    "\n",
    "# SAVE ENCODER MODEL\n",
    "ENC_PATH = MODEL_PATH + \"_enc.pt\"\n",
    "torch.save(encoder.state_dict(), ENC_PATH)\n",
    "\n",
    "# SAVE ENCODER MODEL\n",
    "DEC_PATH =  MODEL_PATH + \"_dec.pt\"\n",
    "torch.save(decoder.state_dict(), DEC_PATH)\n",
    "\n",
    "# RELOAD\n",
    "encoder = Encoder(len(XFIELD.vocab), HIDDEN_SIZE, EMBEDDING_SIZE, NUM_LAYERS)\n",
    "encoder.load_state_dict(torch.load(MODEL_PATH + '_enc.pt', map_location=torch.device('cpu')))\n",
    "\n",
    "decoder = Decoder(len(XFIELD.vocab), HIDDEN_SIZE, EMBEDDING_SIZE, NUM_LAYERS).to(device)\n",
    "decoder.load_state_dict(torch.load(MODEL_PATH + '_dec.pt', map_location=torch.device('cpu')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
