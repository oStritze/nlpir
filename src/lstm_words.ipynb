{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u> LSTM ENCODER DECODER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import numpy as np\n",
    "\n",
    "#utils.setup_nltk()\n",
    "PRESIDENT = 'obama'\n",
    "speeches = utils.read_all_text_files(PRESIDENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_list = [':', '(', ')', ',', '-',]\n",
    "filtered_speeches = []\n",
    "\n",
    "for speech in speeches:\n",
    "    filtered_speech = []\n",
    "    for word in speech:\n",
    "        # filter out unwanted words\n",
    "        if word not in filter_list:\n",
    "            # lower word\n",
    "            filtered_speech.append(word.lower())\n",
    "    filtered_speeches.append(filtered_speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "WINDOW = 5\n",
    "grams = [ngrams(s, WINDOW+1) for s in filtered_speeches]\n",
    "flat_grams = [ng for speech in grams for ng in speech]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X = [' '.join(list(x[0:WINDOW])) for x in flat_grams]\n",
    "Y = [x[-1] for x in flat_grams]\n",
    "df = pd.DataFrame.from_dict({'x':X, 'y':Y})\n",
    "\n",
    "# persist\n",
    "csv_name = '../data/lstm/preproc/{}_encdec_{}grams.csv'.format(PRESIDENT, str(WINDOW))\n",
    "df.to_csv(csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/home/gabriel/.local/lib/python3.8/site-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "/home/gabriel/.local/lib/python3.8/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import torchtext\n",
    "\n",
    "XFIELD = torchtext.data.Field(sequential=True)\n",
    "YFIELD = torchtext.data.Field(sequential=True)\n",
    "DATA = torchtext.data.TabularDataset(csv_name,'csv', \n",
    "                                     [('x', XFIELD),('y', YFIELD)], skip_header=True)\n",
    "\n",
    "XFIELD.build_vocab(DATA)  \n",
    "YFIELD.build_vocab(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.8/site-packages/torchtext/data/iterator.py:48: UserWarning: Iterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import BucketIterator, Iterator\n",
    "import torch\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_iterator = Iterator(DATA, BATCH_SIZE, device=device, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert device.type == 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, embedding_dim, num_layers):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers=num_layers, bidirectional=True)\n",
    "\n",
    "    def forward(self, x, h0, c0):\n",
    "        x = self.embedding(x).unsqueeze(0)\n",
    "        out, (h0, c0) = self.lstm(x, (h0, c0))\n",
    "        return out, (h0, c0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, embedding_dim, num_layers):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers=num_layers, dropout=0.5, bidirectional=True)\n",
    "        self.dense = nn.Linear(hidden_size*2, vocab_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "  \n",
    "    def forward(self, x, h0, c0):\n",
    "        x = self.embedding(x)\n",
    "        x, (h0, c0) = self.lstm(x, (h0, c0))\n",
    "        x = self.dense(x.squeeze(0))\n",
    "        x = self.softmax(x)\n",
    "        return x, (h0, c0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 20\n",
    "EMBEDDING_SIZE = 50\n",
    "NUM_LAYERS = 2\n",
    "LR = 0.01\n",
    "ENC_LEARNING_RATE = LR\n",
    "DEC_LEARNING_RATE = LR\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "encoder = Encoder(len(XFIELD.vocab), HIDDEN_SIZE, EMBEDDING_SIZE, NUM_LAYERS).to(device)\n",
    "decoder = Decoder(len(XFIELD.vocab), HIDDEN_SIZE, EMBEDDING_SIZE, NUM_LAYERS).to(device)\n",
    "enc_optimizer = torch.optim.Adam(encoder.parameters(), lr = ENC_LEARNING_RATE)\n",
    "dec_optimizer = torch.optim.Adam(decoder.parameters(), lr = DEC_LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3593 [00:00<?, ?it/s]/home/gabriel/.local/lib/python3.8/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "100%|█████████▉| 3592/3593 [00:49<00:00, 71.84it/s]\n",
      "  0%|          | 0/3593 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=5.8158, (ABS=20892.94)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3592/3593 [00:55<00:00, 64.87it/s]\n",
      "  0%|          | 0/3593 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=5.2816, (ABS=18973.67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3592/3593 [00:57<00:00, 62.13it/s]\n",
      "  0%|          | 0/3593 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=5.0834, (ABS=18261.69)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3592/3593 [00:59<00:00, 60.58it/s]\n",
      "  0%|          | 0/3593 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=4.9568, (ABS=17807.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3592/3593 [01:00<00:00, 59.21it/s]\n",
      "  0%|          | 0/3593 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=4.8751, (ABS=17513.51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3592/3593 [01:01<00:00, 58.35it/s]\n",
      "  0%|          | 0/3593 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=4.8204, (ABS=17316.87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3592/3593 [01:02<00:00, 57.88it/s]\n",
      "  0%|          | 0/3593 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=4.7694, (ABS=17133.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3592/3593 [01:03<00:00, 56.74it/s]\n",
      "  0%|          | 0/3593 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=4.7362, (ABS=17014.48)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3592/3593 [01:03<00:00, 56.78it/s]\n",
      "  0%|          | 0/3593 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=4.7087, (ABS=16915.77)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3592/3593 [01:04<00:00, 55.58it/s]\n",
      "  0%|          | 0/3593 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=4.697, (ABS=16873.63)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3592/3593 [01:03<00:00, 56.59it/s]\n",
      "  0%|          | 0/3593 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=4.6808, (ABS=16815.44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3592/3593 [01:04<00:00, 55.87it/s]\n",
      "  0%|          | 0/3593 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=4.6725, (ABS=16785.66)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3592/3593 [01:03<00:00, 56.29it/s]\n",
      "  0%|          | 0/3593 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=4.6595, (ABS=16739.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3592/3593 [01:04<00:00, 55.88it/s]\n",
      "  0%|          | 0/3593 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=4.6435, (ABS=16681.43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3592/3593 [01:05<00:00, 55.19it/s]\n",
      "  0%|          | 0/3593 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=4.635, (ABS=16650.88)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3592/3593 [01:04<00:00, 55.75it/s]\n",
      "  0%|          | 0/3593 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=4.6261, (ABS=16618.99)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3592/3593 [01:04<00:00, 55.65it/s]\n",
      "  0%|          | 0/3593 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=4.6113, (ABS=16565.95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3592/3593 [01:05<00:00, 54.81it/s]\n",
      "  0%|          | 0/3593 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=4.6173, (ABS=16587.34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3592/3593 [01:04<00:00, 55.89it/s]\n",
      "  0%|          | 0/3593 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=4.6136, (ABS=16574.12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3592/3593 [01:05<00:00, 55.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=4.6115, (ABS=16566.47)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "EPOCHS = 20\n",
    "for ep in range(EPOCHS):\n",
    "    ep_loss = 0\n",
    "    \n",
    "    for batch in tqdm(train_iterator):\n",
    "        if len(batch) != BATCH_SIZE: break;\n",
    "        inp = batch.x\n",
    "        target = batch.y\n",
    "        \n",
    "        # init\n",
    "        loss = 0\n",
    "        h0 = torch.zeros(NUM_LAYERS*2, BATCH_SIZE, HIDDEN_SIZE).to(device)\n",
    "        c0 = torch.zeros(NUM_LAYERS*2, BATCH_SIZE, HIDDEN_SIZE).to(device)\n",
    "        enc_optimizer.zero_grad()\n",
    "        dec_optimizer.zero_grad()\n",
    "        \n",
    "        # encode\n",
    "        for w in range(inp.size(0)):\n",
    "            enc_out, (h0, c0) = encoder(inp[w], h0, c0)\n",
    "            \n",
    "        # decode\n",
    "        cur = inp[WINDOW-1].unsqueeze(0)\n",
    "        dec_out, (_, _) = decoder(cur, h0, c0)        \n",
    "        cur = torch.argmax(dec_out,dim=1)\n",
    "        \n",
    "        # loss\n",
    "        # target_onehot = torch.nn.functional.one_hot(target.squeeze(), len(YFIELD.vocab))\n",
    "        loss += criterion(dec_out, target.squeeze())\n",
    "        \n",
    "        # optimize\n",
    "        ep_loss += loss\n",
    "        loss.backward()\n",
    "        enc_optimizer.step()\n",
    "        dec_optimizer.step()\n",
    "        \n",
    "    print('AVG_LOSS={}, (ABS={})'.format(round((ep_loss/(len(DATA)/BATCH_SIZE)).item(),4), round(ep_loss.item(),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Text!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import torch\n",
    "\n",
    "def voc_index(words):\n",
    "    return torch.tensor([XFIELD.vocab.stoi[x] for x in words]).to(device)\n",
    "\n",
    "def predict(inp, RND_FACTOR=0, multiply=False, h0=None, c0=None):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        if h0 == None:\n",
    "            h0 = torch.zeros(2*NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE).to(device)\n",
    "        if c0 == None:\n",
    "            c0 = torch.zeros(2*NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE).to(device)\n",
    "        \n",
    "        for w in range(inp.size(0)):\n",
    "                enc_out, (h0, c0) = encoder(inp[w], h0, c0)\n",
    "\n",
    "        cur = inp[WINDOW-1].unsqueeze(0)\n",
    "        dec_out, (h0, c0) = decoder(cur, h0, c0)\n",
    "        \n",
    "        # randomize\n",
    "        if multiply:\n",
    "            rnd = torch.rand(dec_out.shape).to(device) * RND_FACTOR + 1\n",
    "            cur = torch.argmax(dec_out * rnd,dim=1)\n",
    "        else:\n",
    "            rnd = torch.rand(dec_out.shape).to(device) * RND_FACTOR\n",
    "            cur = torch.argmax(dec_out.add(rnd),dim=1)\n",
    "\n",
    "        return YFIELD.vocab.itos[cur[0].item()], (h0, c0)\n",
    "\n",
    "def generate(intro=['good', 'evening', 'ladies', 'and', 'gentlemen'], multiply=False, rnd_factor=10, length=100, decay=None):\n",
    "    text = intro\n",
    "    h0 = torch.zeros(2*NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE).to(device)\n",
    "    c0 = torch.zeros(2*NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE).to(device)\n",
    "    \n",
    "    for i in range(length):\n",
    "        cur_window = text[-WINDOW:]\n",
    "        vecs = voc_index(cur_window).view(WINDOW,1).repeat(1,BATCH_SIZE)\n",
    "        \n",
    "        if decay:\n",
    "            prediction, (h0, c0) = predict(vecs, rnd_factor, multiply, h0, c0)\n",
    "            #h0 = torch.rand(h0.shape).to(device) * h0\n",
    "            #c0 = torch.rand(c0.shape).to(device) * c0\n",
    "        else:\n",
    "            prediction, _ = predict(vecs, rnd_factor, multiply)\n",
    "            \n",
    "        text.append(prediction)\n",
    "\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create N speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 37s, sys: 6.96 s, total: 7min 44s\n",
      "Wall time: 7min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"good evening ladies and gentlemen . and that 's why i 'm going to be clear that we ’ re going to be a nation that are here in the world . and i ’ m here in the world . we must be met in the world . and that 's why we ’ ve been the promise of the world . but i think that we have a more prosperous . and we will not be easy . and that ’ s why we ’ re not the ability to take us to the house . and we must be solved . and we ’ re going to be the same prescriptions . we ’ re not a more perfect . we know that it is not just a whole bunch of leaders of the great law -- and the answer is not a lot of people in the world . and i ’ m not naïve to the world . and we are the united to the united states of america . and that ’ s why i ’ ve been done . and the united states of america . applause . we will be a different for the money . and we ’ re not clear to the world and the taliban have come through a new of law . and that ’ s why i ’ m announcing a lot of . we will be vigilant in the world . it ’ s the reason that will make sure that the world . applause . you have a lot of our kids to prevent . and we will not do the same . and we ’ ve got to do you . applause dr. and the united states . applause . and that 's why we need to the future . and the world is not a nation . and that ’ s why there is the world . and that ’ s why we ’ ve been a lot of posturing and the united states of america . that ’ s why we want to be a nation of our economy and the united states of america . applause . and i ’ m not going to be a country . and that ’ s why i want to thank you 'd be able to be able to be in the way to the united states of america ’ s largest energy and the world . and we can not keep the same line . but i ’ m going to have to do the same and we have to be a realist that 's not a lot of dollars . we can not be a betrayal of conditions . and that ’ s why we ’ ve been . and i ’ m not going to be a result of the way . and i believe that the american people and the united states of america . and we ’ re not going to be a nation . and that ’ s why we ’ ve been . applause . and i ’ m here to be in the way to the united states . and that ’ s why we ’ re not the chance to make sure we have to be a nation . but the way to the united states of america . and i ’ m going to keep the way to the world . and if you ’ re going to make sure that the united states of america . applause . we ’ ve got to happen the american people . it is a lot of dollars . and the united states of america . and that ’ s why we are the right to help the world . applause . we ’ ve got to do . the president well i ’ m announcing to this congress to be a loan tax . and the world that are looking to the american people . but i ’ ve made the power . but i have to do it . and i want to thank you just a few . and i ’ m going to be in the world . and we ’ ve got to the future of the world of the great union can also be a nation that the united states of america ’ s security and the world . and in the world . it ’ s the president and we must have to take it . and we will be a time for a new tax -- the american people are here to get the way to the american people that the united states of america . and i have to make sure that the united states of america . and the question of the american people . and that 's why i ’ m not going to make sure that we ’ re not just in the same thing . applause . i know that we are the first of the united states . and we will come with the same or the same to reduce the afghan government . and i ’ m not going to do you . applause dr. inspiration said that the united states of america . but we ’ re willing to be a nation that ’ s the right thing to the world . we ’ re not been a betrayal of conditions and we ’ ve already said to the world . and we ’ ve made a new job . and that 's why we ’ re not the right thing . applause . now the president well i ’ ve been done . and that ’ s why i ’ m announcing to a nation of our union . and i ’ m not going to help the deficit . applause . we have a lot of dollars . but i have to thank you . applause . thank you . god bless you . god bless you . thank you . god bless you . thank you . god bless you . applause . and we must be solved . but the president well that ’ s the president well the united states of america ’ s largest jobs and the world . and that ’ s why we ’ ve been to make sure i ’ m not not going to be a nation of the streets of our troops . and we ’ re going to be the world . but i ’ m not going to be in the face of the world . it is a lot of americans . applause . and i ’ m going to try to the same and to be a different burden that we have to make a difference . but it 's a lot of americans . and we ’ ve been the same for the same for the right thing to make sure that it ’ s not not an option . applause . we ’ ve got to be a betrayal of conditions . and that ’ s why we are the same . and that ’ s why we need to work . and that ’ s why we 've got to do . and i ’ m here to the american people in the world . applause . and i think that the united states of america . and that ’ s why we want to the same way to the united states . applause . and we ’ re going to be a nation . and i ’ m proposing to the same way to the people who would have to do . the president well that ’ s a time of our troops and a few of our common humanity are the first of the world . and the united states of america . and we will continue to invest in the world . the idea that we are a time to get a difference . applause . and that ’ s why we need to be our children . applause . we will not tolerate the rules . applause . now as we must be a betrayal of conditions . and that 's why i want to make sure that the united states of america . and i ’ m going to keep the same . and we will help us . we have a seat . we can ’ t be met . applause . we ’ ve got to be a realist . but it 's why we ’ re going to god the way to the american people and the way to the united states of america . and to do you . applause . pope is a lot of americans and more than the same for the american people . and we ’ ve a . that ’ s why we ’ re not a seat to the american people . and that ’ s why we ’ ve been . and that 's why i 'm proposing that there is a time of the world and the world is not on the deficit . and that ’ s why i want to mention a new beginning of the same . we will continue to be an outsider to the security of the future of the united states of america . and i know that we ’ re going to be the way to the american people . and that ’ s why we ’ re going to have a lot of tax a trillion dollars of the world is the world . and that ’ s why it 's not much . and that ’ s why i ’ m here tonight is the time . and i will not be a nation of the world . it is not just as a nation of the senate . applause . i think that we ’ ve been the right thing to make sure the world is not possible to the american people . and i ’ m not not accept . we ’ ve got a lot of issues . and a nation the way to the united states of america . it is not a lot of americans . so i ’ m here in the world . and i think that we ’ re going to be a realist to get the way to a world . and i ’ m not going to the same way . that ’ s why i ’ m here to make it . and that ’ s why we are a better who have lost up on the world . and that ’ s why we have a conversation to be in the midst of our union and our troops . applause . and that ’ s why we ’ ve got to make sure that we ’ ve got to do you ’ t . but we have to get a lot of dollars . and i have to do you . applause . pope the world . but the american people ’ s momentum and the united states of america . and i think about the same for the american people . it ’ s the president and we can not be an expression of a decade to the world . and that ’ s why the united states . applause . i have a say to the american people who have been a seat to a family that we ’ re going to be the world . and we can not be a different . but we have a better 30,000 american and well-connected and the united states of america . and we will support the side of a decade . applause . and that ’ s why we ’ ve been a more likely to act the world that are not just a lot of issues . we will make the united states of america . and that ’ s why we have to be an expression of the middle class . applause . and i ’ m here tonight . applause . i think that the united states of america . but the senate gets that we ’ re not about the right thing to do . and i believe that the united states of america . applause . that 's why i 'm announcing this congress to get the way that we have to earn the taliban and the world and i ’ m not going to the american people . and i know that the united states of america . and the united states of america . and we ’ re not a lot of posturing that the american people are here in the world . and that ’ s why we ’ re going to the united states . but that we want the work . and i know that it is a lot of dollars . we can not tolerate a thriving tax for the american people . applause . we ’ ve got to be self-evident of the country . and we ’ re not simply not a new economy . and i think that we ’ re going to be a country . and that 's why we ’ ve been done . and that ’ s why i ’ m announcing talking of the future of the house and the united states of america . and we ’ ve been done . the world i ’ m announcing to our own people . and that ’ s why we ’ ve got to be in the same . and the world will be the same thing . applause . and i ’ m not going to make sure of the future that the united states of america . but i think that the first of the world . and we will make sure that is not only the united states of america . and that ’ s why we ’ ve got to do it . and that ’ s why we have to make sure that we ’ re going to be a nation . and that 's why i ’ ve got to make sure that we ’ re not a betrayal of conditions and the united states of america . and i ’ m not going to keep a new age . applause . we will continue to protect us and the afghan people and the united states of america . and i ’ m not going to be a nation . and that ’ s why we can not be clear by the world . and i ’ m not going to be a nation of opportunity and the united states of america . and we are the united states of america . and it ’ s a result of the same and reinvestment of the way . applause . i ’ m not going to make sure that we ’ ve been the right thing to make sure that the american people are now . it ’ s a nation that a better plan . applause . we have a seat . we will be in the future . applause . and that 's why we need to do . the president well that ’ s why i want to thank you . applause . and we ’ re not a law-abiding usual . and i 'm going to make sure that the united states of america . and that ’ s why we ’ re going to be a nation of the deficit . and we can ’ t do not just . and we are the same for the same . and that ’ s why i ’ m announcing to the future . and we ’ re going to make a difference . but we ’ ve been a lot of dollars . the president well is the same thing to the way that the united states of america . and i ’ m proposing to the future . applause . and we can not be a betrayal of conditions and the united states of america . applause . and that ’ s why we ’ re not clear to the world . and i think about a more lending to work to the world . we ’ re going to be a apocalypse of the best to do you . applause . pope the united states of america ’ s security and the united states . and we are those to the united states of america . applause . now that ’ s what we ’ ve got to talk to the american people . it is the time to come to the world . we ’ re going to be an option . applause . and i ’ m not going to be a nation of the economy and the united states of america ’ s success . and that ’ s why we ’ re not a recipe to the future of the united states of america ’ s largest challenges . and the united states of america . applause . and in the world and the world . applause . we know that the american people are now and the united states of america . applause . and i think that is a lot of . and the united states of america . and the world is not just to the same for the money to get the world . and that ’ s why we ’ re going to be a nation . that ’ s why we ’ ve got to do . the president well that ’ s why we are the same thing to the world . applause . we need to do it . and that ’ s why we are here in the world . we know that we ’ ve already been a chance to the security of the country of the united states of america . and we are a promise that will be a member of the same for the american people . applause . and that ’ s why we ’ re going to be a betrayal of conditions . but we will be more than the right thing to do . and we ’ re not a lot of issues . and we ’ ve got a set of conditions to the afghan government . and i want to speak for the first time . and we do n't do . and i think that is not going to be able to be a country . and we will not be the american people . applause . and that ’ s why you are here tonight is not possible . applause . we have to get a better future on the table . and that ’ s why we need to do the same . but we ’ re going to be a nation of a thriving system . applause . we ’ ve seen that we are here . but that 's why we ’ ve already said to the future and a new age that the united states of america . but we have a seat . and that ’ s why we ’ re going to be a sacred burden of the united states of america . applause . and that 's why we want to be a nation of the world . and it ’ s a place that are now the world . we have to keep our borders . and we can do . applause . i ’ m not going to be in the same . but i ’ m here tonight is to the united states of america . and i ’ ve been laid . and that 's why we ’ re not just a nation of the united states of america . applause . and we will be met by the way to the senate of the people of the american people . and that 's why we are willing to get a new approach to the world . but we ’ ve been . and we must be solved and our troops and the united states of america and the united states of america . and that ’ s why we ’ ve been a more elevated test . and we ’ ve a lot of americans . applause . it is not just a nation of the american people to the american people . applause . and i ’ m not going to be done . applause . and that 's why we ’ ve got to do you the work . and we ’ re doing a new economy . we have to make sure that they ’ ve been . but also i ’ m announcing to the american people . and i think that we ’ ve been the chance . and that 's why i ’ m announcing to a new foundation of the world . and i ’ m going to make sure the way that the united states of america . and i think that to the same of our national security and the great recession . applause . and we will help a new foundation of the globe . applause . and that ’ s why i ’ m announcing to the future . applause . and i ’ m here to the american people . the same officer . we will work to the same and i know that it is the time to the american people . and that ’ s why we have to be the world . i think that is the time to the american people . it ’ s a time of progress is not going to be to the world . and that ’ s why we are a chance to be an outsider . and we ’ ve got to be the american people and that we ’ re doing it . and we must support the afghan people . we ’ ve got a lot of and the next generation of our schools is a lot of dollars . and that ’ s why i think that we have to get the world . and we ’ ve got to make sure that we ’ re not a more perfect . applause . and i know that we are we need to the american people . applause . i know that we ’ re not . it is not not clear that it 's a choice to reduce the afghan people and the united states is not a long that the american people are struggling to the power of america ’ s security and a lot of america . and i ’ m going to be a nation . and i ’ m not going to keep the power . and i want to thank the people of the american people . and that ’ s why we ’ re not been the promise . i ’ m not going to do . and we ’ ve made it . but we will be a betrayal of conditions . applause . i want to thank you the first of all of us . it ’ s a time of the united states of america . and that ’ s why we ’ re trying to got to be a nation that the united states of america . and i ’ m proposing . i ’ m here tonight is not a lot of americans to make sure that we are a lot of posturing that ’ s why we ’ re going to be a long to be . and because i ’ m here in the last few years . and we ’ ve got to do . applause . we know that the united states of america is not a time of the american people are now going to be in the world . but i ’ m n't make sure that we ’ re not a lot of dollars . and that ’ s why we need to stay the promise of the world . and that ’ s why we ’ re not just . and that ’ s why the world is not just the promise of the united states of america . applause . i think about the united states of america and the united states of america . applause . and that 's why we have to go to the same for the same thing in the last few years . applause . so we ’ re not the chance to protect us and they 've been done . and i ’ m not going to be in the future . and we ’ ve been a lot of . and that 's why we ’ ve already been a loan dollars on the future . and that 's why we have a seat . but we will make a difference . but i think that 's why we ’ re not in the country that the united states of america . and we are a lot of americans . and i know that you are not a lot of way . and i want to thank you to join the world . i ’ m here in the past of the economy . applause . i ’ m here to reach a better . and we ’ re not just a loan education . we ’ re going to do . the president well i think that ’ t a system that is not just . and that 's why we ’ ve got . and we ’ re going to be the country . and that ’ s why we ’ ve been done . applause . and that ’ s why the world that are designed to be a nation . it ’ s about the taliban ’ s momentum and the united states of america . and that ’ s why we ’ re doing it . and that 's why i 'm going to try to make sure that the united states of america . and that 's why we ’ re going to be a nation of the world . and the leader of the country . and we ’ ve been a better way to make sure that i ’ m not not not simply . applause . and i believe that the united states of america ’ s security and we ’ ve been to the right of the world . and we ’ ve got to help a system . but the leader of the united states of america . and we are a lot of posturing and the united states of america . and we will continue to work . and i think that 's why we ’ re going to be a apocalypse of our children . we ’ re not a betrayal of conditions of the people and more than the same thing to do it . applause . so i ’ m here in the world . and that ’ s why we ’ re doubt to the world . we can not tolerate a better system . and i ’ ve also . applause . i believe that the way to the world . applause . we have to be a nation of the next system . and we will support the world . and i ’ m not going to be a nation of the american people to the world . it ’ s the right thing to the world . and that ’ s why i want to thank the same way to the future . and i think that is not a mile to the american people to be a nation . and we will not be a long time . and that 's why i ’ m announcing to a future . applause . i ’ m here tonight . and we ’ re not a lot of posturing that ’ s why we ’ re not a lot of dollars . applause . but also we can not be more than the time . we ’ ve made . and i ’ m not going to be a nation . applause . i think that is not a lot of americans . and i ’ m not going to the same line . applause . we ’ re going to make a nation that we have to cut the way to the world and the challenges of the united states of america . applause . and that ’ s why we need to make sure that we ’ re going to be a nation that the american people have been in the way to the world . that 's why we are here tonight is now the way to a new age . and we ’ ve been clear in the world .\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "generated = []\n",
    "GENERATE_N = 10\n",
    "MEAN_OG_SPEECH_LEN = round(np.mean([len(s) for s in speeches]))\n",
    "for i in range(GENERATE_N):\n",
    "    generated.append(\n",
    "        generate(intro=['good', 'evening', 'ladies', 'and', 'gentlemen'], \n",
    "                 multiply=True, \n",
    "                 rnd_factor=1.2, \n",
    "                 length=MEAN_OG_SPEECH_LEN, \n",
    "                 decay=True)\n",
    "    )\n",
    "\n",
    "generated[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean cosine similarity over all generated speeches: 0.046213566006767126\n",
      "standard deviation of cosine similarity over all generated speeches: 0.012049643472512502\n",
      "mean rouge score for all generated speeches: 0.4079794917516292\n",
      "standard deviation of rouge score for all generated speeches: 0.0027243518794677277\n",
      "mean sentence len (OG vs GEN) (18.303574290751722, 11.772115596735054)\n",
      "mean sentence len diff 6.531458694016669\n",
      "mean word len (OG vs GEN) (4.624454002549181, 3.3120036101083032)\n",
      "mean word len diff 1.3124503924408781\n",
      "top15 rank distance 601.2669977824696\n",
      "CPU times: user 49.1 s, sys: 86.7 ms, total: 49.2 s\n",
      "Wall time: 49.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import metrics\n",
    "\n",
    "# persist\n",
    "for i in range(len(generated)):\n",
    "    with open(\"../data/lstm/{}_generated/{}.txt\".format(PRESIDENT, str(i)), \"w\") as text_file:\n",
    "        text_file.write(generated[i]) \n",
    "\n",
    "# scores\n",
    "mean_cos, std_cos, cos_sim = metrics.get_cosine_sim_tfidf(PRESIDENT, \"lstm/{}_generated\".format(PRESIDENT), print_results=True)\n",
    "rouge = metrics.get_rouge_score(PRESIDENT, \"lstm/{}_generated\".format(PRESIDENT), print_results=True)\n",
    "og_sen_len = metrics.calculate_mean_sentence_length(PRESIDENT)\n",
    "gen_sen_len = metrics.calculate_mean_sentence_length(\"lstm/{}_generated\".format(PRESIDENT))\n",
    "print('mean sentence len (OG vs GEN) {}'.format((og_sen_len, gen_sen_len)))\n",
    "print('mean sentence len diff {}'.format(og_sen_len-gen_sen_len))\n",
    "og_w_len = metrics.calculate_mean_word_length(PRESIDENT)\n",
    "gen_w_len = metrics.calculate_mean_word_length(\"lstm/{}_generated\".format(PRESIDENT))\n",
    "print('mean word len (OG vs GEN) {}'.format((og_w_len, gen_w_len)))\n",
    "print('mean word len diff {}'.format(og_w_len-gen_w_len))\n",
    "top = 15\n",
    "rank_dist = metrics.get_top_n_rank_distance(orig_speeches_loc=PRESIDENT, gen_speeches_loc=\"lstm/{}_generated\".format(PRESIDENT), n=top)\n",
    "print('top{} rank distance {}'.format(top, rank_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# make new file names\n",
    "# MODEL_PATH = '../data/obama_models/obama_lstm'\n",
    "\n",
    "# SAVE ENCODER MODEL\n",
    "ENC_PATH = MODEL_PATH + \"_enc.pt\"\n",
    "torch.save(encoder.state_dict(), ENC_PATH)\n",
    "\n",
    "# SAVE ENCODER MODEL\n",
    "DEC_PATH =  MODEL_PATH + \"_dec.pt\"\n",
    "torch.save(decoder.state_dict(), DEC_PATH)\n",
    "\n",
    "# RELOAD\n",
    "encoder = Encoder(len(XFIELD.vocab), HIDDEN_SIZE, EMBEDDING_SIZE, NUM_LAYERS)\n",
    "encoder.load_state_dict(torch.load(MODEL_PATH + '_enc.pt', map_location=torch.device('cpu')))\n",
    "\n",
    "decoder = Decoder(len(XFIELD.vocab), HIDDEN_SIZE, EMBEDDING_SIZE, NUM_LAYERS).to(device)\n",
    "decoder.load_state_dict(torch.load(MODEL_PATH + '_dec.pt', map_location=torch.device('cpu')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
