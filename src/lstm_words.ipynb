{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u> LSTM ENCODER DECODER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import numpy as np\n",
    "\n",
    "#utils.setup_nltk()\n",
    "PRESIDENT = 'all_presidents'\n",
    "speeches = utils.read_all_text_files(PRESIDENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_list = [':', '(', ')', ',', '-',]\n",
    "filtered_speeches = []\n",
    "\n",
    "for speech in speeches:\n",
    "    filtered_speech = []\n",
    "    for word in speech:\n",
    "        # filter out unwanted words\n",
    "        if word not in filter_list:\n",
    "            # lower word\n",
    "            filtered_speech.append(word.lower())\n",
    "    filtered_speeches.append(filtered_speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "WINDOW = 5\n",
    "grams = [ngrams(s, WINDOW+1) for s in filtered_speeches]\n",
    "flat_grams = [ng for speech in grams for ng in speech]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X = [' '.join(list(x[0:WINDOW])) for x in flat_grams]\n",
    "Y = [x[-1] for x in flat_grams]\n",
    "df = pd.DataFrame.from_dict({'x':X, 'y':Y})\n",
    "\n",
    "# persist\n",
    "csv_name = '../data/lstm/preproc/{}_encdec_{}grams.csv'.format(PRESIDENT, str(WINDOW))\n",
    "df.to_csv(csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/home/gabriel/.local/lib/python3.8/site-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "/home/gabriel/.local/lib/python3.8/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import torchtext\n",
    "\n",
    "XFIELD = torchtext.data.Field(sequential=True)\n",
    "YFIELD = torchtext.data.Field(sequential=True)\n",
    "DATA = torchtext.data.TabularDataset(csv_name,'csv', \n",
    "                                     [('x', XFIELD),('y', YFIELD)], skip_header=True)\n",
    "\n",
    "XFIELD.build_vocab(DATA)  \n",
    "YFIELD.build_vocab(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.8/site-packages/torchtext/data/iterator.py:48: UserWarning: Iterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import BucketIterator, Iterator\n",
    "import torch\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_iterator = Iterator(DATA, BATCH_SIZE, device=device, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert device.type == 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, embedding_dim, num_layers):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers=num_layers, bidirectional=True)\n",
    "\n",
    "    def forward(self, x, h0, c0):\n",
    "        x = self.embedding(x).unsqueeze(0)\n",
    "        out, (h0, c0) = self.lstm(x, (h0, c0))\n",
    "        return out, (h0, c0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, embedding_dim, num_layers):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers=num_layers, dropout=0.5, bidirectional=True)\n",
    "        self.dense = nn.Linear(hidden_size*2, vocab_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "  \n",
    "    def forward(self, x, h0, c0):\n",
    "        x = self.embedding(x)\n",
    "        x, (h0, c0) = self.lstm(x, (h0, c0))\n",
    "        x = self.dense(x.squeeze(0))\n",
    "        x = self.softmax(x)\n",
    "        return x, (h0, c0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 20\n",
    "EMBEDDING_SIZE = 50\n",
    "NUM_LAYERS = 2\n",
    "LR = 0.01\n",
    "ENC_LEARNING_RATE = LR\n",
    "DEC_LEARNING_RATE = LR\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "encoder = Encoder(len(XFIELD.vocab), HIDDEN_SIZE, EMBEDDING_SIZE, NUM_LAYERS).to(device)\n",
    "decoder = Decoder(len(XFIELD.vocab), HIDDEN_SIZE, EMBEDDING_SIZE, NUM_LAYERS).to(device)\n",
    "enc_optimizer = torch.optim.Adam(encoder.parameters(), lr = ENC_LEARNING_RATE)\n",
    "dec_optimizer = torch.optim.Adam(decoder.parameters(), lr = DEC_LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12754 [00:00<?, ?it/s]/home/gabriel/.local/lib/python3.8/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "100%|█████████▉| 12753/12754 [04:43<00:00, 44.93it/s]\n",
      "  0%|          | 0/12754 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=5.8125, (ABS=74130.76)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 12753/12754 [04:53<00:00, 43.46it/s]\n",
      "  0%|          | 0/12754 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=5.4616, (ABS=69656.11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 12753/12754 [04:59<00:00, 42.58it/s]\n",
      "  0%|          | 0/12754 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=5.3577, (ABS=68331.25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 12753/12754 [05:04<00:00, 41.89it/s]\n",
      "  0%|          | 0/12754 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=5.3032, (ABS=67635.52)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 12753/12754 [05:18<00:00, 40.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG_LOSS=5.2765, (ABS=67294.72)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "EPOCHS = 5\n",
    "for ep in range(EPOCHS):\n",
    "    ep_loss = 0\n",
    "    \n",
    "    for batch in tqdm(train_iterator):\n",
    "        if len(batch) != BATCH_SIZE: break;\n",
    "        inp = batch.x\n",
    "        target = batch.y\n",
    "        \n",
    "        # init\n",
    "        loss = 0\n",
    "        h0 = torch.zeros(NUM_LAYERS*2, BATCH_SIZE, HIDDEN_SIZE).to(device)\n",
    "        c0 = torch.zeros(NUM_LAYERS*2, BATCH_SIZE, HIDDEN_SIZE).to(device)\n",
    "        enc_optimizer.zero_grad()\n",
    "        dec_optimizer.zero_grad()\n",
    "        \n",
    "        # encode\n",
    "        for w in range(inp.size(0)):\n",
    "            enc_out, (h0, c0) = encoder(inp[w], h0, c0)\n",
    "            \n",
    "        # decode\n",
    "        cur = inp[WINDOW-1].unsqueeze(0)\n",
    "        dec_out, (_, _) = decoder(cur, h0, c0)        \n",
    "        cur = torch.argmax(dec_out,dim=1)\n",
    "        \n",
    "        # loss\n",
    "        # target_onehot = torch.nn.functional.one_hot(target.squeeze(), len(YFIELD.vocab))\n",
    "        loss += criterion(dec_out, target.squeeze())\n",
    "        \n",
    "        # optimize\n",
    "        ep_loss += loss\n",
    "        loss.backward()\n",
    "        enc_optimizer.step()\n",
    "        dec_optimizer.step()\n",
    "        \n",
    "    print('AVG_LOSS={}, (ABS={})'.format(round((ep_loss/(len(DATA)/BATCH_SIZE)).item(),4), round(ep_loss.item(),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Text!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import torch\n",
    "\n",
    "def voc_index(words):\n",
    "    return torch.tensor([XFIELD.vocab.stoi[x] for x in words]).to(device)\n",
    "\n",
    "def predict(inp, RND_FACTOR=0, multiply=False, h0=None, c0=None):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        if h0 == None:\n",
    "            h0 = torch.zeros(2*NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE).to(device)\n",
    "        if c0 == None:\n",
    "            c0 = torch.zeros(2*NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE).to(device)\n",
    "        \n",
    "        for w in range(inp.size(0)):\n",
    "                enc_out, (h0, c0) = encoder(inp[w], h0, c0)\n",
    "\n",
    "        cur = inp[WINDOW-1].unsqueeze(0)\n",
    "        dec_out, (h0, c0) = decoder(cur, h0, c0)\n",
    "        \n",
    "        # randomize\n",
    "        if multiply:\n",
    "            rnd = torch.rand(dec_out.shape).to(device) * RND_FACTOR + 1\n",
    "            cur = torch.argmax(dec_out * rnd,dim=1)\n",
    "        else:\n",
    "            rnd = torch.rand(dec_out.shape).to(device) * RND_FACTOR\n",
    "            cur = torch.argmax(dec_out.add(rnd),dim=1)\n",
    "\n",
    "        return YFIELD.vocab.itos[cur[0].item()], (h0, c0)\n",
    "\n",
    "def generate(intro=['good', 'evening', 'ladies', 'and', 'gentlemen'], multiply=False, rnd_factor=10, length=100, decay=None):\n",
    "    text = intro\n",
    "    h0 = torch.zeros(2*NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE).to(device)\n",
    "    c0 = torch.zeros(2*NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE).to(device)\n",
    "    \n",
    "    for i in range(length):\n",
    "        cur_window = text[-WINDOW:]\n",
    "        vecs = voc_index(cur_window).view(WINDOW,1).repeat(1,BATCH_SIZE)\n",
    "        \n",
    "        if decay:\n",
    "            prediction, (h0, c0) = predict(vecs, rnd_factor, multiply, h0, c0)\n",
    "            #h0 = torch.rand(h0.shape).to(device) * h0\n",
    "            #c0 = torch.rand(c0.shape).to(device) * c0\n",
    "        else:\n",
    "            prediction, _ = predict(vecs, rnd_factor, multiply)\n",
    "            \n",
    "        text.append(prediction)\n",
    "\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create N speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 33s, sys: 7.41 s, total: 14min 40s\n",
      "Wall time: 14min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"good evening ladies and gentlemen . and we ’ re going to be able to get a lot of people . and i ’ m going to be to be able to be done . applause . and i think that i ’ ve got to be in the first time and the people will be an example that they ’ re not going to be a better of the world and i 've made a very tough time that we ’ re going to do it . i ’ m also want to help the time of the world . the president well i ’ m going to be able to get to a new future . we will not be the same time . the president i ’ m sure that is the way that they can not be the most important system to be a lot of years . we will not be a new nation . and the president i have a little bit of the first . and we ’ re going to be able to make sure that the united states is a little bit . and i am pleased to be able to make sure that we have to have the same time and the united states is not a lot of of the same and i ’ ve been a lot of the next few years ago that we will not protect the first time of the middle east . i ’ ve been a good of the same time and you will be a better . it ’ s a lot of people . and i want to thank the president . and i have a lot of time . they ’ re going to be a very good of the world . applause . and we have the president to the american people . and i ’ m in the world . it is a lot of the middle east and we ’ re going to be able to be able to keep to our country . and i ’ m not want to be able to be done . i ’ ve seen . we ’ re going to be able to have the way . and we ’ re not a better time . we have to see the same time that are the first time of the middle east and our nation . we ’ re going to be done . applause . and we will continue to be a new time . and the president . and i think a great thing that we have a better job . and they ’ re going to be done . and i know the president the president well i ’ ve been able to be able to do you . applause . and we ’ re going to be able to get a little bit of our country . and i am a lot of of the american people . we will not help the american people . and i ’ m also ’ t have to have on the united states of the last two weapons . applause . and i want to be a lot of time . and we have to be able to have a lot of the united states . and i ’ ve got to be able to be done . this is a few years . they ’ ve seen . and we ’ re going to be able to have a better job . we will be a better of a year that they ’ re not going to be able to take in the world . we ’ re going to be able to be able to the world . and we ’ re also that the united states is the united states . and we have the president . it was the same time . and i ’ ve been told to do . and the president . but we have a lot of the people . i ’ ve ever made to be able to keep the first time that they want to be easy . and i ’ m a little bit of the first time . and the president we ’ re going to be a good . and i think that i would be a little bit that they have to have a new way . and we ’ re going to be able to make the same . and we ’ re going to be able to do the right thing to make sure that i know that we have to get the first time . it ’ s been a big of of thousands of our people and to be done . and we ’ re going to be able to build a new time . and the president i ’ m the first time of the world . they have to be able to the american people . we are working with the same time . and we ’ re going to be able to have more than a nation . we will be the same time . we will work to work to the american people . i want to thank you . applause . and i ’ m going to be able to make sure that ’ s not going to be able to make sure that we will be the first time of the last two time . the president . i will be no coincidence . and i don ’ t know that they will be a better deal . and that 's why i ’ m going to get to the world . we can be substance the way to the world . and we ’ re going to be able to see the president that we are the most of a new course of the united states . and that ’ s not not the way . the president well i ’ ve made to be able to the world . i think the president well i ’ m not only the first time . it ’ s a great of people . we have to keep the american people . we have to be a big of a new time that we have to the world . we ’ re going to be able to get a new people . and we will be the american people . it 's been a lot of the way that are a better of the way . and we ’ re going to be able to be able to the first time of the past and we have to come to the world . we ’ re going to be done . we are the president . we ’ re going to be a little bit . the president . thank you . mr. president . we ’ re going to be able to be done . and i ’ ve been . we ’ re going to be able to be able to get a very big time that will be a new future . the president . and i ’ ve got a lot of people to be able to see the same people of the world . and we have been . we have a lot of people . and we are all about the first time . we ’ ve been going to be a good job . we ’ re going to be a very good to the president . we can be fauci . and we can do . applause . it ’ s been a new nation that we can be cornyn . and we have . and i am going to do we have a great of people . and i have a little bit of the same people . and i ’ m not want to make sure that we ’ re going to be able to get a better of the world . we must have a lot of of dollars and the united states . applause . and we ’ re going to be able to protect the way of the american people . and i 've made a lot of people . and that ’ s why i think that we are the same time . we have to be able to work . and the president . the president . and i ’ ve been talking to see the united states . and i have a very tough of a year of the past . and we ’ re doing with the time of the first time . and we ’ re going to be able to do not keep a new future . and the president well i ’ ve got to do not be a great time . and i have a good to take a nation and they have to make sure that we have a very good to be allowed to get to our citizens . and i ’ m going to be able to be able to take the world . i ’ m going to be done . we will not the day of the first time . and we ’ re going to be able to be able to the president . we can ’ t be able to do not the world . i ’ m going to make sure that we are the first time of the world . and we ’ re going to be able to be able to do you know we have to do it . and i know we ’ re not going to be able to help our country . they ’ ve been proud . and we ’ re going to be done . and i have a very proud of the world . we ’ re going to be able to be done . and i ’ ve been able to get to the president . we ’ re going to be able to get a new nation . the president well you don ’ t want to be a big of the people . but we ’ re going to do you about the united states . and i ’ ve been a proud of our nation . and we ’ re going to be able to make sure that the president we ’ re going to be able to be able to make sure that we ’ re going to be done . applause . the president well i ’ ve got a new american of the first thing . but i ’ m going to have to be able to protect our own of jobs and our country . i will ’ t to have a little bit of the last three years . we can be mad . and i ’ m believe of the way that we ’ re going to be very much . i ’ m going to be able to be able to . we can not be proud . and i know we have been a new nation . and the president i ’ m going to be able to be able to the world . they ’ re going to be able to be able to do n't think that ’ s a lot of americans and we have the same time . we are doing a better . applause . and we ’ re doing that it ’ s the president that we ’ re going to be able to get to the people . and the president well i think that we are not . we are the first time . and we ’ re going to be able to see it . and we ’ re going to be used to be a lot of sure we can make sure that we have to make sure that we have the president . it is a great time . and i want to thank the united states of the world . and that ’ s why i will have been able to do not have a lot of of dollars . and we ’ re going to be able to be able to the american people and i am going to be able to be done . but i ’ ve been talking about . and we will be able to make sure that will be a lot of people . we can ’ t have a new way . in the world of the world . they ’ re going to be able to be able to the world . we ’ re going to be a very good of it . and that ’ s why that we have to go to the world . it 's a big thing . and it ’ s a great of people . and i ’ m going to be able to get in the first time . and i ’ m going to make sure that we have a new new way . and i ’ ve been a tremendous of of the world . and that ’ s why i ’ m n't the same of the united states . and we will make sure that we have to be to be able to get that . and it 's time that we have been to be able to have a new new policy of the world and i ’ m a very big . we can ’ t have a very good . applause . and i think that ’ s why i ’ ve seen to the people and we must not be able to the american people . the president i don ’ t have a lot of people . and we have been done . applause . the president . and i 'm saying that we will never be a big of the world . and we are a little bit of the world . and it is a lot of people . we ’ re going to be able to be a lot of people . and we have to be able to make sure that we will be a good to work . we ’ re going to be able to make sure that they ’ re going to be done . we have a little bit . and that ’ s why i said “ you know i ’ ve made to have to be the people . we ’ re going to be done . we are going to be able to get the way . but we have a new great of people . we ’ re going to be easy . applause . and we ’ re going to be easy . and we ’ re going to be able to be a new people of the same time . it ’ s been a very good of it . we have a little bit . and i want to thank the president . thank you . and i ’ ve seen . and it is a lot of people . and it is a lot of time . and we ’ re doing to work and to make sure that we ’ re going to be able to make sure that ’ s not the first time of the world . we are the first time . and i believe that the most important news we have proposed in the first time . it 's been the first time that we are going to be able to have to the middle east . and that 's why we ’ re going to be able to come to the united states . and the president . and i ’ m want to know we ’ re doing that the world is the president that we ’ re going to be able to make sure that we ’ re going to be able to be able to do not the same time that we ’ re going to be able to be a little bit of the world . i am a lot of jobs . and the president . and i ’ ve been able to get to a big of the american people . they ’ re going to be able to be able to do the right that we ’ re going to be able to get a little bit . but i will be made to be fair . i know the president we will be on the country . i don ’ t know that 's been not happening . but we have to be able to the world . it is the way . and we ’ re going to be to be able to see the same time of the world . and we ’ re going to be able to the world . and i have to do the president . i ’ ve seen to be able to work and to do you that we ’ re going to be able to be able to the greatest job . and we are not the same time . applause . the president . and it 's been that we ’ re going to be able to make sure that we have to do we have a lot of of the united states and the american people . and that 's why i said “ that ’ s why the president . q the president . i ’ m going to be a little bit . and i think that ’ s why that is a nation that i said “ it was a lot of time . applause . and we ’ re going to be able to the world . we are going to have a lot of people to make sure that we are a very little bit . and we ’ re going to be able to get to the american people . applause . and the president i ’ ve been a little bit . and i will not be the way . we have to be able to be able to be able to be able to be able to find a nation . we will continue to keep the world . we ’ re going to be a proud of time . the president i ’ m going to be done . we ’ re going to be able to see the same nation . the president . thank you . thank you . applause . and i ’ m that . we ’ re going to be able to be able to make sure that was no coincidence to see the american people . we are a very difficult time . we will not be to be done . we ’ re going to be able to be able to be a big thing . and we ’ re going to be able to do not be a little bit . and that ’ s why we have a new nation . we have to be able to do it . and the world will be and have a better of the first war . and i ’ ve made a great way . and we ’ re going to be able to make sure that is the president . i 'm going to be able to be a new nation . and we will not do . we ’ re not doing a very tough of it . we ’ re going to be able to see a long time of the first . the president . applause . the president well the president . we ’ re going to be able to do the right . the president i ’ m doing the president that we ’ re going to do you that that ’ s why the president the president well i said “ we ’ re going to be able to see a very simple of a new way . and i 'm proud to be proud to be able to get a new time and i ’ m want to do not do the right . and we ’ re going to be able to be done . and i said “ i ’ m going to be able to see the world . and we ’ re going to be a very good . we will be a time of the worst of the world . and that ’ s why that ’ s not that the first time to do . and i know that we can ’ t have to get the world . we ’ re going to be able to make sure that the president i have been to be a lot of of dollars . and i am not going to be able to help the world . and we will be a lot of of dollars . and i ’ m have been the same time . and i don ’ t have to have a great thing . and i ’ ve been able to be able to make sure that this is the president . i know that we have to make sure that we will continue to be able to protect the world . and we will have a better of a lot of of thousands of dollars and i believe the president the president is the way . we ’ re going to be a lot of of the american people . it ’ s going to be proud . and we ’ re going to be able to be able to get a good . and in the next few years . it ’ s a lot of a lot of the time . it ’ s a great thing . we have the american people . and we have a great of the people . the president well i have a lot of people . we have a lot of people . and i ’ ve made to do you know that you ’ ve made to do not know i ’ m not going to be able to be done . i ’ ve got the first time . the president well i ’ m going to be to be done . and we ’ re going to be able to be a strong of the american people and the most important and the president of the last few years ago the world . we are the people . applause . we ’ re going to be able to get the world . and we ’ re going to be a tough of of the world . and we have to be able to find our allies . i ’ ve been able to be done . and that ’ s why that we have a lot of of thousands of american citizens . and the president is a lot of people . and the president well i said “ the president we have a new day . and the president . and i ’ m have been to make sure that we ’ re going to be able to have a great job . applause . i want to thank you . thank you . applause . and that ’ s why that is a good of our nation . we can not be the time . and we have the president . applause . i ’ ve been . and i ’ m not going to do the right thing that 's why we ’ re going to be able to be able to the most important way . and i think that we are very much the united states of the american time . and i ’ m going to do not get a new time . and i have a very good of the world . we can ’ t be a lot of a time of the people . and in the last few years . it 's been to be a new nation that we can not be able to the world . the president i want to do you that we are the way to the president . but i ’ m going to be able to protect the united states and to protect the american people . we have been able to help . and we ’ re going to be able to be able to the president . and i said “ i can be birx . and we have to be a better . and we ’ re going to be a great and the president the president . we ’ ve been going to be able to be done . and i ’ m not a very very proud of people and our children in the last few years ago that we will not be able to be able to make sure that the president the president well i said “ that 's why i have a tough of of thousands of people and the united states of the american people . applause . i want to thank the fact that i ’ ve been proud to be a sense of the american people . and i ’ ve seen that the first thing . but i have a time . the president . but we have to do you ’ re doing about . and we ’ re also not a lot of of the united states . the president well the president we have a new nation . and that ’ s why i ’ ve got a lot of of dollars . we will be a better way to the world . and we ’ re going to be able to be able to the world . and i ’ ve made the president . and we have the world . the president i ’ ve been in the president . i ’ ve been able to be able to make sure that they want to do the president . q i have a very good of the american people . we ’ re going to be a testament to the american people . we ’ re going to be able to do the right thing . the president i 'm told the most important of people . we are doing a big job . the president the president i ’ ve seen to be able to help the first time . in the last few years ago of the world and we are to make sure that we ’ re going to be able to get the first time . and we ’ re going to be able to be able to work to the future of our country . and we ’ re going to be able to be a better of the world and i ’ ve been a great of a time of the united of our nation . and we ’ re going to be a very great . and i ’ ve seen . and the president i ’ ve been a very difficult time . we have been the first time . but they want to thank the president . q q mr. president . and i ’ m not going to be able to take it . and we ’ re going to be a very tough time . we can make the first time . and i ’ m going to be able to get a big . and i want to be seated for our country . and they ’ ve made to the american people . and i want to be able to be able\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "generated = []\n",
    "GENERATE_N = 10\n",
    "MEAN_OG_SPEECH_LEN = round(np.mean([len(s) for s in speeches]))\n",
    "for i in range(GENERATE_N):\n",
    "    generated.append(\n",
    "        generate(intro=['good', 'evening', 'ladies', 'and', 'gentlemen'], \n",
    "                 multiply=True, \n",
    "                 rnd_factor=1.2, \n",
    "                 length=MEAN_OG_SPEECH_LEN, \n",
    "                 decay=True)\n",
    "    )\n",
    "\n",
    "generated[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean cosine similarity over all generated speeches: 0.02953504805110054\n",
      "standard deviation of cosine similarity over all generated speeches: 0.0025794384238498626\n",
      "mean rouge score for all generated speeches: 0.33438683818603077\n",
      "standard deviation of rouge score for all generated speeches: 0.0028675752317295538\n",
      "mean sentence len (OG vs GEN) (16.104933341524852, 13.232704402515724)\n",
      "mean sentence len diff 2.872228939009128\n",
      "mean word len (OG vs GEN) (4.663221710255911, 3.1107356745042294)\n",
      "mean word len diff 1.5524860357516816\n",
      "top15 rank distance 237.66452801239785\n",
      "CPU times: user 2min 54s, sys: 562 ms, total: 2min 54s\n",
      "Wall time: 2min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import metrics\n",
    "\n",
    "# persist\n",
    "for i in range(len(generated)):\n",
    "    with open(\"../data/lstm/{}_generated/{}.txt\".format(PRESIDENT, str(i)), \"w\") as text_file:\n",
    "        text_file.write(generated[i]) \n",
    "\n",
    "# scores\n",
    "mean_cos, std_cos, cos_sim = metrics.get_cosine_sim_tfidf(PRESIDENT, \"lstm/{}_generated\".format(PRESIDENT), print_results=True)\n",
    "rouge = metrics.get_rouge_score(PRESIDENT, \"lstm/{}_generated\".format(PRESIDENT), print_results=True)\n",
    "og_sen_len = metrics.calculate_mean_sentence_length(PRESIDENT)\n",
    "gen_sen_len = metrics.calculate_mean_sentence_length(\"lstm/{}_generated\".format(PRESIDENT))\n",
    "print('mean sentence len (OG vs GEN) {}'.format((og_sen_len, gen_sen_len)))\n",
    "print('mean sentence len diff {}'.format(og_sen_len-gen_sen_len))\n",
    "og_w_len = metrics.calculate_mean_word_length(PRESIDENT)\n",
    "gen_w_len = metrics.calculate_mean_word_length(\"lstm/{}_generated\".format(PRESIDENT))\n",
    "print('mean word len (OG vs GEN) {}'.format((og_w_len, gen_w_len)))\n",
    "print('mean word len diff {}'.format(og_w_len-gen_w_len))\n",
    "top = 15\n",
    "rank_dist = metrics.get_top_n_rank_distance(orig_speeches_loc=PRESIDENT, gen_speeches_loc=\"lstm/{}_generated\".format(PRESIDENT), n=top)\n",
    "print('top{} rank distance {}'.format(top, rank_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# make new file names\n",
    "# MODEL_PATH = '../data/obama_models/obama_lstm'\n",
    "\n",
    "# SAVE ENCODER MODEL\n",
    "ENC_PATH = MODEL_PATH + \"_enc.pt\"\n",
    "torch.save(encoder.state_dict(), ENC_PATH)\n",
    "\n",
    "# SAVE ENCODER MODEL\n",
    "DEC_PATH =  MODEL_PATH + \"_dec.pt\"\n",
    "torch.save(decoder.state_dict(), DEC_PATH)\n",
    "\n",
    "# RELOAD\n",
    "encoder = Encoder(len(XFIELD.vocab), HIDDEN_SIZE, EMBEDDING_SIZE, NUM_LAYERS)\n",
    "encoder.load_state_dict(torch.load(MODEL_PATH + '_enc.pt', map_location=torch.device('cpu')))\n",
    "\n",
    "decoder = Decoder(len(XFIELD.vocab), HIDDEN_SIZE, EMBEDDING_SIZE, NUM_LAYERS).to(device)\n",
    "decoder.load_state_dict(torch.load(MODEL_PATH + '_dec.pt', map_location=torch.device('cpu')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
